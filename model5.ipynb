{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define classes and functions to collect user and business data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "maxInt = sys.maxsize\n",
    "decrement = True\n",
    "\n",
    "while decrement:\n",
    "    decrement = False\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)\n",
    "        decrement = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['user_average_stars', 'user_review_count', 'user_useful', 'business_price_range', 'business_review_count', 'business_stars']\n",
    "print_mod = 1000\n",
    "# over 150000 rows in train_reviews\n",
    "train_data_size = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the current date\n",
    "current_date = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User():\n",
    "    def __init__(self, average_stars, review_count, useful):\n",
    "        self.average_stars = average_stars\n",
    "        self.review_count = review_count\n",
    "        self.useful = useful\n",
    "\n",
    "class Business():\n",
    "    def __init__(self, price_range, review_count, stars):\n",
    "        self.price_range = price_range\n",
    "        self.review_count = review_count\n",
    "        self.stars = stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_users():\n",
    "    with open('users.csv', newline='') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        next(csv_reader)\n",
    "        users = {}\n",
    "        for row in csv_reader:\n",
    "            average_stars = row[0]\n",
    "            review_count = row[18]\n",
    "            useful = row[19]\n",
    "            user_id = row[20]\n",
    "            if not user_id in users:\n",
    "                users[user_id] = User(average_stars, review_count, useful)\n",
    "        print('collected users')\n",
    "        return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_businesses():\n",
    "    with open('business.csv', newline='') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        next(csv_reader)\n",
    "        businesses = {}\n",
    "        for row in csv_reader:\n",
    "            if row[34]:\n",
    "                price_range = row[34]\n",
    "            else:\n",
    "                price_range = random.randint(1,4)\n",
    "            business_id = row[41]\n",
    "            review_count = row[58]\n",
    "            stars = row[59]\n",
    "            if not business_id in businesses:\n",
    "                businesses[business_id] = Business(price_range, review_count, stars)\n",
    "        print('collected businesses')\n",
    "        return businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(users, businesses):\n",
    "    # open train_reviews.csv\n",
    "    train_reviews_df = pd.read_csv(\"train_reviews.csv\", header=0)\n",
    "\n",
    "    # delete columns: review_id, text, cool, date, funny, useful\n",
    "    del train_reviews_df['review_id'], train_reviews_df['text'], train_reviews_df['cool'], train_reviews_df['date'], train_reviews_df['funny'], train_reviews_df['useful']\n",
    "\n",
    "    # truncate rows\n",
    "    train_reviews_df = train_reviews_df.truncate(after=train_data_size)\n",
    "\n",
    "    # create empty x_train with named rows\n",
    "    x_train = pd.DataFrame(columns=features, dtype=float)\n",
    "\n",
    "    # convert user_id and business_id using maps\n",
    "    train_index = 0\n",
    "    start = time.time()\n",
    "    for index, row in train_reviews_df.iterrows():\n",
    "        if not train_index % print_mod and train_index:\n",
    "            print('total rows:', train_index, 'last iteration:', '{0:.2f}'.format(time.time() - start))\n",
    "            start = time.time()\n",
    "\n",
    "        x_train.loc[index] = [users[row['user_id']].average_stars, users[row['user_id']].review_count, users[row['user_id']].useful, businesses[row['business_id']].price_range, businesses[row['business_id']].review_count, businesses[row['business_id']].stars]\n",
    "        train_index += 1\n",
    "\n",
    "    # split train_reviews_df into features and training\n",
    "    y_train = train_reviews_df.stars\n",
    "\n",
    "    print('collected train data')\n",
    "    \n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create objects and collect data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected users\n"
     ]
    }
   ],
   "source": [
    "users = get_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected businesses\n"
     ]
    }
   ],
   "source": [
    "businesses = get_businesses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows: 1000 last iteration: 1.94\n",
      "total rows: 2000 last iteration: 1.95\n",
      "total rows: 3000 last iteration: 2.40\n",
      "total rows: 4000 last iteration: 3.18\n",
      "total rows: 5000 last iteration: 2.42\n",
      "total rows: 6000 last iteration: 2.91\n",
      "total rows: 7000 last iteration: 3.11\n",
      "total rows: 8000 last iteration: 4.64\n",
      "total rows: 9000 last iteration: 3.94\n",
      "total rows: 10000 last iteration: 2.92\n",
      "total rows: 11000 last iteration: 3.28\n",
      "total rows: 12000 last iteration: 4.53\n",
      "total rows: 13000 last iteration: 4.98\n",
      "total rows: 14000 last iteration: 4.92\n",
      "total rows: 15000 last iteration: 5.08\n",
      "collected train data\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = get_train_data(users, businesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the net funtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net(x_train, y_train):\n",
    "    # instantiate the model with two hidden layers of size 6 and 2\n",
    "    net = MLPClassifier(hidden_layer_sizes=(6,2))\n",
    "\n",
    "    # fit the model with data\n",
    "    net.fit(x_train, y_train)\n",
    "\n",
    "    print('created net')\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_queries_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_validate_queries():\n",
    "    # open validate_queries\n",
    "    validate_queries_df = pd.read_csv(\"validate_queries.csv\", header=0)\n",
    "\n",
    "    # truncate rows\n",
    "    validate_queries_df = validate_queries_df.truncate(after=validate_queries_size)\n",
    "\n",
    "    # delete columns: unnamed\n",
    "    del validate_queries_df['Unnamed: 0']\n",
    "\n",
    "    # create empty x_test with named rows\n",
    "    x_test = pd.DataFrame(columns=features, dtype=float)\n",
    "\n",
    "    train_index = 0\n",
    "    start = time.time()\n",
    "    for index, row in validate_queries_df.iterrows():\n",
    "        if not train_index % print_mod and train_index:\n",
    "            print('total rows:', train_index, 'last iteration:', '{0:.2f}'.format(time.time() - start))\n",
    "            start = time.time()\n",
    "\n",
    "        x_test.loc[index] = [users[row['user_id']].average_stars, users[row['user_id']].review_count, users[row['user_id']].useful, businesses[row['business_id']].price_range, businesses[row['business_id']].review_count, businesses[row['business_id']].stars]\n",
    "        train_index += 1\n",
    "\n",
    "    # extract stars from validate_queries\n",
    "    y_test = validate_queries_df.stars\n",
    "    \n",
    "    return x_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows: 1000 last iteration: 1.97\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = run_validate_queries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and score a net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created net\n",
      "mean accuracy score: 27.87%\n"
     ]
    }
   ],
   "source": [
    "net = get_net(x_train, y_train)\n",
    "print('mean accuracy score: {:.2%}'.format(net.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run net on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ran on validate queries, rmse: 1.2666473875533018\n"
     ]
    }
   ],
   "source": [
    "# predict on testing set\n",
    "y_pred = net.predict(x_test)\n",
    "\n",
    "square_error = 0\n",
    "for index, row in y_test.iteritems():\n",
    "    square_error += numpy.square(row - y_pred[index])\n",
    "\n",
    "rmse = numpy.sqrt(square_error / len(y_pred))\n",
    "print('ran on validate queries, rmse:', rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
